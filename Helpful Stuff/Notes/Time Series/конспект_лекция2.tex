\documentclass[]{article}

%opening
\title{Конспект лекции 2}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{multirow,array}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{dsfont}
\usepackage{mathabx}
\usepackage{pgfplots}
\usepackage{booktabs} 
\usepackage{mathtext}
\usepackage{framed}
\usepackage{graphicx}
\pgfplotsset{compat=1.16}
\DeclareMathOperator*{\E}{\mathbb{E}}
\DeclareMathOperator*{\LT}{\mathcal{L}}
\author{Buchko Daniil, BEC175}

\begin{document}
	\maketitle
	
\subsection*{Небольшое отступление по поводу решения разностных уравнений}	
Если у нас имеется initial state, то мы вправе разворачивать уравнение индукционно и итоговый ответ будет решением разностного уравнения. Но если начального условия нет, то разворачивание не будет решением.\\\\
Пусть имеется уравнение:
\[
	y_t = \alpha_0 + \alpha_1y_{t-1} + \varepsilon_{t}
\]
Если его проитерировать, то получим:
\begin{gather*}
\boxed{	y_t = \alpha_1^ty_0 + \alpha_0\sum_{i=0}^{t-1}\alpha_1^i + \sum_{i=0}^{t-1}\alpha_1^{i}\varepsilon_{t-i}}
\end{gather*}
Имея начальные условия, можно было бы подставить их вместо $ y_0 $, чтобы получить выражение $ y_t $, как функцию, выраженную через его начальное состояние. Но в данном примере $ y_0 $ неизвестно и, следовательно, мы должны продолжить разворачивать уравнение:
\begin{gather*}
 y_0 = \alpha_0 + \alpha_1 y_{-1}+\varepsilon_{0} \\
 y_t = \alpha_1^ty_0 + \alpha_0\sum_{i=0}^{t-1}\alpha_1^i + \sum_{i=0}^{t-1}\alpha_1^{i}\varepsilon_{t-i} \\
 y_t = \alpha_1^t\left( \alpha_0 + \alpha_1 y_{-1}+\varepsilon_{0}\right) + \alpha_0\sum_{i=0}^{t-1}\alpha_1^i + \sum_{i=0}^{t-1}\alpha_1^{i}\varepsilon_{t-i}  \\
 y_t = \alpha_1^{t+1}y_{-1} + \alpha_0\sum_{i=0}^{t-1+1}\alpha_1^i + \sum_{i=0}^{t-1+1}\alpha_1^{i}\varepsilon_{t-i} \\
 y_t = \alpha_1^{t+m}y_{-m} + \alpha_0\sum_{i=0}^{t-1+m}\alpha_1^i + \sum_{i=0}^{t-1+m}\alpha_1^{i}\varepsilon_{t-i}
\end{gather*}
Теперь, полагая, что $ m\to\infty $, в то время, как $ |\alpha_1| < 1 $, можем заметить, что итоговое уравнение при бесконечном разложении будет сходиться к:
\begin{gather*}
	\boxed{
		y_t = \frac{\alpha_0}{1 - \alpha_1} + \sum_{i=0}^{\infty}\alpha_1^i\varepsilon_{t-i}
	}
\end{gather*}
Можно легко убедиться в том, что полученное выражение является решением разностного уравнения, подставив его в начальное выражение:
\begin{align*}
 \frac{\alpha_0}{1 - \alpha_1} + \sum_{i=0}^{\infty}\alpha_1^i\varepsilon_{t-i} &= \alpha_0 + \alpha_1 \left[\frac{\alpha_0}{1 - \alpha_1} + \sum_{i=0}^{\infty}\alpha_1^i\varepsilon_{t-1-i} \right] + \varepsilon_t \\
 \frac{\alpha_0}{1 - \alpha_1} + \sum_{i=0}^{\infty}\alpha_1^i\varepsilon_{t-i} &=  \frac{\alpha_0}{1 - \alpha_1} + \sum_{i=0}^{\infty}\alpha_1^{i+1}\varepsilon_{t-1-i}  + \varepsilon_t \\
 \sum_{i=0}^{\infty}\alpha_1^i\varepsilon_{t-i} &= \sum_{i=0}^{\infty}\alpha_1^{i+1}\varepsilon_{t-1-i}  + \varepsilon_t
\end{align*}
Последняя строчка тождественно выполняется. Но почему же это не решение? В процессе развертки исходного разностного уравнения, мы предполагали, что $ \lim_{m\to\infty} \alpha_1^{t+m}y_{-m} = 0 $, поэтому любое дополнительно слагаемое вида $ A\alpha_1^t $ не повлияет на решение разностного уравнения:
\begin{align*}
y_t := Aa_1^t + \frac{a_0}{1-a_1} + \sum_{i=0}^{\infty}a_1^i\varepsilon_{t-i} &= a_0 + a_1\left[Aa_1^{t-1}+\frac{a_0}{1-a_1} + \sum_{i=0}^{\infty}a_1^i\varepsilon_{t-1-i}\right] + \varepsilon_t\\
\sum_{i=0}^{\infty}a_1^i\varepsilon_{t-i} &=\sum_{i=0}^{\infty}a_1^i\varepsilon_{t-1-i} +\varepsilon_t
\end{align*}
Последняя строка выполняется как тождество. \\\\
Предположим теперь, что нам стало известно начальное условие $ y_0 $, которое выполняется в период времени $ t=0 $. Покажем, что бесконечная развертка легко превращается в решение, полученное в самом начале: 
\begin{align*}
y_0 &= Aa_1^0 + \frac{a_0}{1-a_1} + \sum_{i=0}^{\infty}a_1\varepsilon_{t-i}\\
&= A + \frac{a_0}{1-a_1} + \sum_{i=0}^{\infty}a_1\varepsilon_{t-i}
\end{align*}
Выразим $ A $:
\[
	A = y_0 -  \frac{a_0}{1-a_1} - \sum_{i=0}^{\infty}a_1\varepsilon_{t-i}
\]
Теперь подставим его в бесконечную развертку:
\begin{align*}
y_t = \left[y_0 -  \frac{a_0}{1-a_1} - \sum_{i=0}^{\infty}a_1\varepsilon_{t-i}\right]a_1^t +\frac{\alpha_0}{1 - \alpha_1} + \sum_{i=0}^{\infty}\alpha_1^i\varepsilon_{t-i} 
\end{align*}
упростив, получим решение разностного уравнения:
\begin{gather*}
	\boxed{y_t = \left[ y_0 -  \frac{a_0}{1-a_1} \right] a_1^t+ \frac{a_0}{1-a_1} + \sum_{i=0}^{t-1}\alpha_1^i\varepsilon_{t-i} }
\end{gather*}
А если раскроем скобки и аккуратно сделаем финт с пределами сумм, то получим изначальное индуктивное решение:
\begin{gather*}
\boxed{	y_t = \alpha_1^ty_0 + \alpha_0\sum_{i=0}^{t-1}\alpha_1^i + \sum_{i=0}^{t-1}\alpha_1^{i}\varepsilon_{t-i}}
\end{gather*}
\subsubsection*{Случай, когда $ |a_1| >1 $}
Если имеем, что $ |a_1| > 1 $, то уже нельзя разложить уравнение в бесконечную сумму, потому что мы пользовались формулой суммы геометрической прогрессии. Но индуктивное разложение все еще работает.
\subsubsection*{Случай, когда $ a_1 =1 $}
Исходное разностное уранение первого порядка теперь примет вид:
\[
	y_t = a_0 + y_{t-1} + \varepsilon_t
\]
Пользуясь индуктивным разложением при известных начальных условиях, получим, что решение будет иметь вид:
\[
	y_t = y_0 + a_0t + \sum_{i=0}^{t}\varepsilon_{t-i}
\]
Заметим, что в отличие от уравнения первого порядка, здесь влияние шума не уменьшается со временем.
\section*{Решение разностных уравнений 2-го порядка}
Имеем однородное разностное уравнение вида:
\begin{equation}\label{второй порядок}
	y_t = a_1y_{t-1} + a_2y_{t-2}
\end{equation}
Чтобы его решить, составляется характеристическое уравнение:
\[
	\lambda^2 - a_1\lambda - a_2 = 0
\]
Решив характеристичесоке уравнение относительно $ \lambda  $ получим:
\[
	\lambda_{1,2} = \frac{a_1 \pm \sqrt{d}}{2}, \quad where ~~d = a_1^2 +4a_2
\]
Форма однородного решения зависит от значения $ \lambda $:
\begin{enumerate}
	\item Если $ d > 0 $, тогда однородное решение будет иметь вид: 
	\[
		y^{h}_{t} = A_1(\lambda_{1})^t + A_2 (\lambda_{2})^t
	\]
	\item Если $ d = 0 $:
	\[ 	y^{h}_{t} =  A_1(\lambda_{1})^t + A_2t (\lambda_{1})^t	\]
	\item Если $ d < 0 $:
	\[
		y^{h}_{t} = \beta_1r^{t}\cos(\theta t + \beta_2), \quad r = \sqrt{-a_2}, \quad\theta{:} ~ \cos(\theta) = \frac{a_1}{2\sqrt{-a_2}}
	\]
\end{enumerate}
\section*{Лаговый оператор}
По определению лаговый оператор это:
\[	
	L^{i}y_t = y_{t-i}
\]
\textbf{Свойства лагового оператора:}
\begin{enumerate}
	\item $ Lconst = const $
	\item $ (L^{i} + L^{j})y_t = y_{t-i} + y_{t-j} $
	\item $ L^{i}L^{j}y_t = y_{t-i-j} $
	\item $ L^{-i}y_t = y_{t+i} $
	\item Для $ |a| <1 $: $ (1 + aL + a^2L^2 + \dots )y_t  = \frac{y_t}{1-aL}$
	\item Для $ |a| > 1 $: $ [1 + (aL)^{-1} + (aL)^{-2} + \dots]y_t = \frac{y_t}{1 - 1/aL} = -\frac{aLy_t}{1-aL} $
\end{enumerate}
\textbf{Нахождение particular solution, используя лаговые операторы}.
Найдем частное решение для модели
\[
	y_t = a_0 + a_1 y_{t-1} + \varepsilon_{t}
\]
\begin{align*}
y_t - a_1 y_{t-1} &= a_0 + \varepsilon_{t}\\
(1 -a_1L)y_t &= a_0+ \varepsilon_{t} \\
y_t &= \frac{a_0+ \varepsilon_{t}}{1-aL}\\
y_t&=(a_0 + \varepsilon_{t})\sum_{i=0}^{\infty}(aL)^{i} \\
y_t&= \sum_{i=0}^{\infty}a^iL^ia_0 + \sum_{i=0}^{\infty}a^iL^i\varepsilon_t \\
y_t &= a_0\sum_{i=0}^{\infty}a^i + \sum_{i=0}^{\infty}a^i\varepsilon_{t-i}
\end{align*}
\end{document}