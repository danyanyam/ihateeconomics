{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28051797.329232562\n",
      "1 23931208.22344046\n",
      "2 23542614.18892489\n",
      "3 23408498.551968083\n",
      "4 21422103.837112475\n",
      "5 17142518.849975973\n",
      "6 11938358.443706807\n",
      "7 7444777.068303665\n",
      "8 4417414.444738898\n",
      "9 2640979.611424666\n",
      "10 1666136.4984679765\n",
      "11 1131366.2220868915\n",
      "12 826717.8039549686\n",
      "13 641080.9495490635\n",
      "14 518573.99343109626\n",
      "15 431371.2703409762\n",
      "16 365509.0238187737\n",
      "17 313468.2032678287\n",
      "18 271124.067404908\n",
      "19 235951.54145159913\n",
      "20 206350.00618635415\n",
      "21 181222.62728973705\n",
      "22 159802.1048421493\n",
      "23 141373.58081658307\n",
      "24 125450.15252979532\n",
      "25 111623.51836291935\n",
      "26 99570.37293338255\n",
      "27 89036.29457790358\n",
      "28 79795.9618657381\n",
      "29 71671.20209554258\n",
      "30 64512.60237354849\n",
      "31 58177.17209626183\n",
      "32 52560.50447373785\n",
      "33 47566.9326328094\n",
      "34 43120.8860146566\n",
      "35 39149.25521968766\n",
      "36 35595.39116500631\n",
      "37 32410.793773484635\n",
      "38 29550.403989945087\n",
      "39 26979.195324329987\n",
      "40 24663.243322417795\n",
      "41 22573.594520204708\n",
      "42 20685.419809987892\n",
      "43 18976.122176769255\n",
      "44 17425.947428134918\n",
      "45 16020.600071619667\n",
      "46 14743.189639444394\n",
      "47 13581.00989711117\n",
      "48 12521.341319884235\n",
      "49 11555.144779875527\n",
      "50 10672.398449699966\n",
      "51 9865.704010905882\n",
      "52 9126.892066764616\n",
      "53 8450.072460849342\n",
      "54 7828.979253889573\n",
      "55 7258.813412156775\n",
      "56 6734.6773410891365\n",
      "57 6252.413348174557\n",
      "58 5808.607972811958\n",
      "59 5399.935636698363\n",
      "60 5022.878581182264\n",
      "61 4674.973592347936\n",
      "62 4353.461007215987\n",
      "63 4056.1242180197423\n",
      "64 3781.2304684170954\n",
      "65 3526.7428860985337\n",
      "66 3290.9028484590526\n",
      "67 3072.301673060435\n",
      "68 2869.476346451419\n",
      "69 2681.3560621653314\n",
      "70 2506.633496319979\n",
      "71 2344.2464683376234\n",
      "72 2193.3421615300595\n",
      "73 2053.5089190395647\n",
      "74 1923.3201672347755\n",
      "75 1802.1092396176596\n",
      "76 1689.122424684102\n",
      "77 1583.7663322181804\n",
      "78 1485.4803461220508\n",
      "79 1393.7577590399262\n",
      "80 1308.129252524446\n",
      "81 1228.136318048334\n",
      "82 1153.3898100358654\n",
      "83 1083.4914110523741\n",
      "84 1018.1231434866854\n",
      "85 956.969871352336\n",
      "86 899.7137105045105\n",
      "87 846.1239522371679\n",
      "88 795.9178746490842\n",
      "89 748.8683478642291\n",
      "90 704.7790451044629\n",
      "91 663.4230120091656\n",
      "92 624.649718582085\n",
      "93 588.2600797216026\n",
      "94 554.1028088225567\n",
      "95 522.0510364007614\n",
      "96 491.9386824074367\n",
      "97 463.6839973467129\n",
      "98 437.13589465890755\n",
      "99 412.19037527113954\n",
      "100 388.73898937610534\n",
      "101 366.6767232134463\n",
      "102 345.9319246691102\n",
      "103 326.41388442772427\n",
      "104 308.0515751716687\n",
      "105 290.7684580147403\n",
      "106 274.49324437042856\n",
      "107 259.17228196998724\n",
      "108 244.74125086287233\n",
      "109 231.1505299796317\n",
      "110 218.34585000899807\n",
      "111 206.27454244343534\n",
      "112 194.89646567238492\n",
      "113 184.16779120922553\n",
      "114 174.05987291283031\n",
      "115 164.53496694872368\n",
      "116 155.54950881685195\n",
      "117 147.07152876017219\n",
      "118 139.0712756082657\n",
      "119 131.5286207901333\n",
      "120 124.40580846439425\n",
      "121 117.68181266804453\n",
      "122 111.33288958503093\n",
      "123 105.33914515576387\n",
      "124 99.681407745763\n",
      "125 94.33492947400532\n",
      "126 89.2824478341766\n",
      "127 84.50791053235601\n",
      "128 79.99832063627821\n",
      "129 75.73594357039605\n",
      "130 71.70771575478854\n",
      "131 67.89882118184988\n",
      "132 64.29715706633529\n",
      "133 60.89400324825043\n",
      "134 57.67394021304582\n",
      "135 54.62920980829868\n",
      "136 51.74919686972376\n",
      "137 49.024640098994055\n",
      "138 46.4481642398418\n",
      "139 44.00992647717273\n",
      "140 41.702429880978826\n",
      "141 39.51881512051718\n",
      "142 37.452922434626146\n",
      "143 35.49691087970393\n",
      "144 33.645223730213026\n",
      "145 31.892412093776386\n",
      "146 30.233501485272406\n",
      "147 28.66278575865148\n",
      "148 27.17492565450169\n",
      "149 25.7660602829415\n",
      "150 24.431515706601218\n",
      "151 23.168329858420055\n",
      "152 21.971665174768262\n",
      "153 20.83787560161341\n",
      "154 19.763513899984517\n",
      "155 18.745897064161223\n",
      "156 17.78171126273136\n",
      "157 16.86802236812461\n",
      "158 16.00215252159079\n",
      "159 15.181510349243563\n",
      "160 14.403688671339957\n",
      "161 13.666278249181584\n",
      "162 12.96745384297208\n",
      "163 12.305219364422417\n",
      "164 11.677215314058198\n",
      "165 11.081833503414579\n",
      "166 10.517186548201362\n",
      "167 9.982069079389936\n",
      "168 9.474671917344292\n",
      "169 8.993278536404137\n",
      "170 8.53672834927031\n",
      "171 8.103799742217369\n",
      "172 7.69327697960721\n",
      "173 7.303863036226703\n",
      "174 6.934397104760709\n",
      "175 6.583938383970883\n",
      "176 6.251507610167769\n",
      "177 5.936051543049628\n",
      "178 5.636808931076248\n",
      "179 5.352996713006551\n",
      "180 5.083590712452687\n",
      "181 4.827865813629792\n",
      "182 4.585199253234759\n",
      "183 4.355035998350943\n",
      "184 4.136482474511691\n",
      "185 3.9290757590177714\n",
      "186 3.7321819387636888\n",
      "187 3.5453731050443755\n",
      "188 3.3679845951320413\n",
      "189 3.199595234748422\n",
      "190 3.0397998394108576\n",
      "191 2.8880532130749903\n",
      "192 2.7439639170475276\n",
      "193 2.6071772968262357\n",
      "194 2.4773031088871753\n",
      "195 2.3539553570578935\n",
      "196 2.2368698774159235\n",
      "197 2.1256254385023166\n",
      "198 2.020064687834635\n",
      "199 1.9197591964751521\n",
      "200 1.8244805451029327\n",
      "201 1.7340228550025496\n",
      "202 1.6481464752638297\n",
      "203 1.5665312868258585\n",
      "204 1.488983084319417\n",
      "205 1.4153565300522992\n",
      "206 1.3453841699940186\n",
      "207 1.2789214407579315\n",
      "208 1.215796639878391\n",
      "209 1.1558177364104898\n",
      "210 1.0988154038964335\n",
      "211 1.0446541245352163\n",
      "212 0.9932106852505141\n",
      "213 0.9443314468311259\n",
      "214 0.8978852234216869\n",
      "215 0.8537431422935985\n",
      "216 0.8117897841754629\n",
      "217 0.7719188227910064\n",
      "218 0.734038219176783\n",
      "219 0.698034843446542\n",
      "220 0.6638207379599511\n",
      "221 0.6312884117698789\n",
      "222 0.600377454023968\n",
      "223 0.5709893509628234\n",
      "224 0.5430573831333461\n",
      "225 0.5165088964214142\n",
      "226 0.49127334962606994\n",
      "227 0.46727641015128846\n",
      "228 0.44446867530152145\n",
      "229 0.4227858117238469\n",
      "230 0.40216367473037806\n",
      "231 0.3825631695145843\n",
      "232 0.36392744022188467\n",
      "233 0.34621146520040824\n",
      "234 0.3293643207403433\n",
      "235 0.3133460921983632\n",
      "236 0.29810881200271455\n",
      "237 0.2836211297206106\n",
      "238 0.26984969245158374\n",
      "239 0.25675367246310427\n",
      "240 0.2442944970596159\n",
      "241 0.2324465409842179\n",
      "242 0.22117543578319626\n",
      "243 0.2104584199845302\n",
      "244 0.20026920913653895\n",
      "245 0.19057361590427857\n",
      "246 0.18135332272146112\n",
      "247 0.1725814840454985\n",
      "248 0.16423814464116454\n",
      "249 0.15630554984150546\n",
      "250 0.1487563469810938\n",
      "251 0.14157371915110833\n",
      "252 0.13474348203238323\n",
      "253 0.12824456241417295\n",
      "254 0.12206211916769448\n",
      "255 0.11618047063521147\n",
      "256 0.11058295624152478\n",
      "257 0.1052572050922696\n",
      "258 0.1001925581513106\n",
      "259 0.09537383468996505\n",
      "260 0.09078658013361945\n",
      "261 0.0864235105547975\n",
      "262 0.08227065161972398\n",
      "263 0.07831991269023347\n",
      "264 0.07456117363071896\n",
      "265 0.07098303475288918\n",
      "266 0.06757851532059748\n",
      "267 0.06433793412269811\n",
      "268 0.06125373104759928\n",
      "269 0.05832169823029221\n",
      "270 0.05553040353349157\n",
      "271 0.05287362752620511\n",
      "272 0.05034636176305052\n",
      "273 0.04793961674171102\n",
      "274 0.045650407765173664\n",
      "275 0.04347007557371314\n",
      "276 0.04139471977471891\n",
      "277 0.03941987200407164\n",
      "278 0.037539204744454574\n",
      "279 0.03574998652456127\n",
      "280 0.03404620611999444\n",
      "281 0.03242375257014386\n",
      "282 0.030879828879056763\n",
      "283 0.029410099374350462\n",
      "284 0.028010692148383913\n",
      "285 0.026678385783819307\n",
      "286 0.025409699072880373\n",
      "287 0.024202165694382\n",
      "288 0.023052240367775895\n",
      "289 0.021957628133914584\n",
      "290 0.020915172804583534\n",
      "291 0.019922267361357895\n",
      "292 0.018977364689673336\n",
      "293 0.01807728149777367\n",
      "294 0.0172206420356643\n",
      "295 0.016404439803105172\n",
      "296 0.015627177511241555\n",
      "297 0.014887190942885417\n",
      "298 0.01418233911669407\n",
      "299 0.01351127346460956\n",
      "300 0.012872143791393505\n",
      "301 0.012263551153490464\n",
      "302 0.011683946968273623\n",
      "303 0.011131815561768295\n",
      "304 0.010606013268990676\n",
      "305 0.010105105773210204\n",
      "306 0.009627985355514172\n",
      "307 0.009173621444957291\n",
      "308 0.008740850582809703\n",
      "309 0.008328858825000712\n",
      "310 0.00793616526499108\n",
      "311 0.00756217759278035\n",
      "312 0.007205913923431407\n",
      "313 0.0068665827848323775\n",
      "314 0.006543389145291027\n",
      "315 0.006235327862867439\n",
      "316 0.00594202471420191\n",
      "317 0.005662541881388044\n",
      "318 0.0053963585017351885\n",
      "319 0.005142722590453305\n",
      "320 0.004901056786273228\n",
      "321 0.004670816395538959\n",
      "322 0.004451481351061836\n",
      "323 0.004242601698929444\n",
      "324 0.004043487989154144\n",
      "325 0.003853852410575948\n",
      "326 0.0036730637598689562\n",
      "327 0.0035008876565351607\n",
      "328 0.003336840054769835\n",
      "329 0.0031804647102408345\n",
      "330 0.003031483860022591\n",
      "331 0.002889532377529469\n",
      "332 0.00275429376185352\n",
      "333 0.002625451041558006\n",
      "334 0.002502625671365985\n",
      "335 0.002385552479927369\n",
      "336 0.002274031857530585\n",
      "337 0.0021677578845408895\n",
      "338 0.002066469501313918\n",
      "339 0.0019699260828941\n",
      "340 0.001877952914854728\n",
      "341 0.001790272787204329\n",
      "342 0.0017067576036230462\n",
      "343 0.0016271088328996125\n",
      "344 0.001551224943145448\n",
      "345 0.0014788831957057253\n",
      "346 0.0014099520081460393\n",
      "347 0.0013442501153257355\n",
      "348 0.0012816209669996646\n",
      "349 0.0012219324882762653\n",
      "350 0.001165029691080281\n",
      "351 0.0011108150591326298\n",
      "352 0.0010591191046307035\n",
      "353 0.0010098486782252189\n",
      "354 0.0009628767767935172\n",
      "355 0.0009181069078194402\n",
      "356 0.0008754492597082843\n",
      "357 0.0008347648781164175\n",
      "358 0.0007959831271203784\n",
      "359 0.0007590147340580187\n",
      "360 0.0007237679681381319\n",
      "361 0.0006901764514135153\n",
      "362 0.0006581434848976688\n",
      "363 0.0006276052437609675\n",
      "364 0.0005984949506173898\n",
      "365 0.0005707472517754158\n",
      "366 0.000544297754114072\n",
      "367 0.0005190783201866847\n",
      "368 0.0004950269499421837\n",
      "369 0.0004720967734054177\n",
      "370 0.0004502423043938457\n",
      "371 0.00042939326134482206\n",
      "372 0.00040951782437496654\n",
      "373 0.0003905680050846392\n",
      "374 0.0003725029546619287\n",
      "375 0.00035528021622714413\n",
      "376 0.0003388526268000327\n",
      "377 0.00032318804179902016\n",
      "378 0.00030825787594879975\n",
      "379 0.0002940193905672646\n",
      "380 0.00028043925074007687\n",
      "381 0.00026748968470092084\n",
      "382 0.00025514037690958855\n",
      "383 0.00024336647750849806\n",
      "384 0.00023214108106179505\n",
      "385 0.00022143124090064775\n",
      "386 0.0002112192768022696\n",
      "387 0.00020148067626929867\n",
      "388 0.00019219585655248588\n",
      "389 0.00018333982749058268\n",
      "390 0.00017489351462432462\n",
      "391 0.000166837904239372\n",
      "392 0.00015915755657227313\n",
      "393 0.00015183260406783034\n",
      "394 0.00014484283412492815\n",
      "395 0.0001381785152429809\n",
      "396 0.00013182100885244442\n",
      "397 0.00012576019309011024\n",
      "398 0.00011997724948394513\n",
      "399 0.00011446194131771244\n",
      "400 0.00010920094196563329\n",
      "401 0.00010418463265298241\n",
      "402 9.940107947027573e-05\n",
      "403 9.48369303917704e-05\n",
      "404 9.048257271692897e-05\n",
      "405 8.63281385598448e-05\n",
      "406 8.236827875490853e-05\n",
      "407 7.858835091131909e-05\n",
      "408 7.498330462186838e-05\n",
      "409 7.154471818334983e-05\n",
      "410 6.826522359895624e-05\n",
      "411 6.513698378766446e-05\n",
      "412 6.215162519908313e-05\n",
      "413 5.930388424725864e-05\n",
      "414 5.658741352735209e-05\n",
      "415 5.399736276702757e-05\n",
      "416 5.152480440182784e-05\n",
      "417 4.9166794874960676e-05\n",
      "418 4.691670523738905e-05\n",
      "419 4.477067200434831e-05\n",
      "420 4.272349684652702e-05\n",
      "421 4.076932457741555e-05\n",
      "422 3.890541778092382e-05\n",
      "423 3.71271692558125e-05\n",
      "424 3.5430664836594446e-05\n",
      "425 3.381193663712655e-05\n",
      "426 3.22671949737725e-05\n",
      "427 3.079376623786197e-05\n",
      "428 2.9388529119283643e-05\n",
      "429 2.8047204806046746e-05\n",
      "430 2.6767162765391473e-05\n",
      "431 2.554570920511682e-05\n",
      "432 2.438094028607892e-05\n",
      "433 2.3268979130258634e-05\n",
      "434 2.2207983843144526e-05\n",
      "435 2.1195459678512868e-05\n",
      "436 2.0229623556723667e-05\n",
      "437 1.9307977040436122e-05\n",
      "438 1.8428466371241397e-05\n",
      "439 1.7589246368426288e-05\n",
      "440 1.678832920023272e-05\n",
      "441 1.6024395962015086e-05\n",
      "442 1.5295036849797968e-05\n",
      "443 1.4598874771012105e-05\n",
      "444 1.3934743865927157e-05\n",
      "445 1.3301041853669456e-05\n",
      "446 1.269617411562976e-05\n",
      "447 1.211902462570688e-05\n",
      "448 1.156819284516858e-05\n",
      "449 1.104261464143258e-05\n",
      "450 1.0540948507547997e-05\n",
      "451 1.0062085539075532e-05\n",
      "452 9.605085541670085e-06\n",
      "453 9.168997250550897e-06\n",
      "454 8.752955403521012e-06\n",
      "455 8.355685263450043e-06\n",
      "456 7.976486977754006e-06\n",
      "457 7.614701811087467e-06\n",
      "458 7.269466472197428e-06\n",
      "459 6.939820043021794e-06\n",
      "460 6.625149583599783e-06\n",
      "461 6.324831748783769e-06\n",
      "462 6.038265567574344e-06\n",
      "463 5.764689266877277e-06\n",
      "464 5.503545559439553e-06\n",
      "465 5.25425424017283e-06\n",
      "466 5.016436568759334e-06\n",
      "467 4.789503698416319e-06\n",
      "468 4.572702265765574e-06\n",
      "469 4.365784857109516e-06\n",
      "470 4.168289386985273e-06\n",
      "471 3.979788000443028e-06\n",
      "472 3.799824217994676e-06\n",
      "473 3.62798594161023e-06\n",
      "474 3.4640288116690415e-06\n",
      "475 3.307508362582025e-06\n",
      "476 3.158071704400451e-06\n",
      "477 3.0154294855212176e-06\n",
      "478 2.8792308194347697e-06\n",
      "479 2.7492608180531666e-06\n",
      "480 2.625163545370683e-06\n",
      "481 2.5066690514283816e-06\n",
      "482 2.3935603225442044e-06\n",
      "483 2.285598768949874e-06\n",
      "484 2.1824909907509222e-06\n",
      "485 2.084075124537876e-06\n",
      "486 1.990113535017582e-06\n",
      "487 1.9004443363183636e-06\n",
      "488 1.814788713123043e-06\n",
      "489 1.7330021407195662e-06\n",
      "490 1.6549298747801074e-06\n",
      "491 1.5804039629766365e-06\n",
      "492 1.5092269434056783e-06\n",
      "493 1.4412825086989667e-06\n",
      "494 1.3764091662544204e-06\n",
      "495 1.3144894378971248e-06\n",
      "496 1.2553619050713022e-06\n",
      "497 1.1988760134330327e-06\n",
      "498 1.1449591526470204e-06\n",
      "499 1.093481650125456e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# N - размер батча, \n",
    "# D_in - размерность входного слоя\n",
    "# H - размерность скрытого слоя\n",
    "# D_out - размерность выходного слоя\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Создаём случайные входные данные и выходные данные\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Инициализируем случайным образом веса\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "# Настраиваем параметры обучения\n",
    "learning_rate = 1e-6\n",
    "epochs = 500\n",
    "\n",
    "# Описываем цикл обучения\n",
    "for epoch in range(epochs):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # подсчитываем loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(epoch, loss)\n",
    "    \n",
    "    # Backproping, чтобы подсчитать dL/dw1; dl/dw2\n",
    "    grad_y_pred = 2 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # обновляем веса\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29461972.0\n",
      "1 26082846.0\n",
      "2 25723544.0\n",
      "3 24630016.0\n",
      "4 21053866.0\n",
      "5 15547498.0\n",
      "6 10022070.0\n",
      "7 5972076.0\n",
      "8 3509021.5\n",
      "9 2156890.5\n",
      "10 1427217.375\n",
      "11 1022271.875\n",
      "12 781352.625\n",
      "13 626164.5625\n",
      "14 518029.28125\n",
      "15 437557.46875\n",
      "16 374728.125\n",
      "17 324041.5625\n",
      "18 282239.9375\n",
      "19 247254.78125\n",
      "20 217683.78125\n",
      "21 192457.28125\n",
      "22 170828.5625\n",
      "23 152198.15625\n",
      "24 136049.625\n",
      "25 122007.6328125\n",
      "26 109740.46875\n",
      "27 98985.46875\n",
      "28 89527.703125\n",
      "29 81176.5703125\n",
      "30 73782.953125\n",
      "31 67214.796875\n",
      "32 61365.4140625\n",
      "33 56141.1484375\n",
      "34 51458.9921875\n",
      "35 47258.03125\n",
      "36 43480.53125\n",
      "37 40075.0390625\n",
      "38 36998.0703125\n",
      "39 34211.87109375\n",
      "40 31688.28515625\n",
      "41 29394.611328125\n",
      "42 27304.8984375\n",
      "43 25398.375\n",
      "44 23656.169921875\n",
      "45 22061.65625\n",
      "46 20599.37109375\n",
      "47 19255.4453125\n",
      "48 18018.73046875\n",
      "49 16878.28125\n",
      "50 15825.970703125\n",
      "51 14853.3984375\n",
      "52 13953.12109375\n",
      "53 13118.9365234375\n",
      "54 12344.537109375\n",
      "55 11625.185546875\n",
      "56 10956.14453125\n",
      "57 10332.83984375\n",
      "58 9752.2734375\n",
      "59 9210.20703125\n",
      "60 8703.861328125\n",
      "61 8230.7861328125\n",
      "62 7787.86181640625\n",
      "63 7372.9931640625\n",
      "64 6984.1162109375\n",
      "65 6619.13623046875\n",
      "66 6276.53125\n",
      "67 5954.703125\n",
      "68 5651.89306640625\n",
      "69 5366.953125\n",
      "70 5098.50927734375\n",
      "71 4845.5087890625\n",
      "72 4606.9365234375\n",
      "73 4381.69140625\n",
      "74 4169.091796875\n",
      "75 3968.4423828125\n",
      "76 3778.83349609375\n",
      "77 3599.509521484375\n",
      "78 3429.84521484375\n",
      "79 3269.0859375\n",
      "80 3116.77001953125\n",
      "81 2972.41796875\n",
      "82 2835.70556640625\n",
      "83 2706.108642578125\n",
      "84 2583.0888671875\n",
      "85 2466.24267578125\n",
      "86 2355.24072265625\n",
      "87 2249.73828125\n",
      "88 2149.44970703125\n",
      "89 2054.049072265625\n",
      "90 1963.2822265625\n",
      "91 1876.96533203125\n",
      "92 1794.7359619140625\n",
      "93 1716.410400390625\n",
      "94 1641.8387451171875\n",
      "95 1570.740478515625\n",
      "96 1502.9580078125\n",
      "97 1438.368896484375\n",
      "98 1376.775146484375\n",
      "99 1317.9884033203125\n",
      "100 1261.90283203125\n",
      "101 1208.3773193359375\n",
      "102 1157.266845703125\n",
      "103 1108.4774169921875\n",
      "104 1061.886962890625\n",
      "105 1017.3887939453125\n",
      "106 974.8468017578125\n",
      "107 934.1978149414062\n",
      "108 895.3707275390625\n",
      "109 858.2221069335938\n",
      "110 822.7327270507812\n",
      "111 788.7802734375\n",
      "112 756.297607421875\n",
      "113 725.22314453125\n",
      "114 695.4889526367188\n",
      "115 667.0419921875\n",
      "116 639.8121337890625\n",
      "117 613.741943359375\n",
      "118 588.7822265625\n",
      "119 564.8950805664062\n",
      "120 542.00390625\n",
      "121 520.088623046875\n",
      "122 499.11004638671875\n",
      "123 478.9931640625\n",
      "124 459.7259216308594\n",
      "125 441.26666259765625\n",
      "126 423.5728454589844\n",
      "127 406.6153564453125\n",
      "128 390.36505126953125\n",
      "129 374.78668212890625\n",
      "130 359.8496398925781\n",
      "131 345.523193359375\n",
      "132 331.791015625\n",
      "133 318.6257019042969\n",
      "134 305.99493408203125\n",
      "135 293.8837890625\n",
      "136 282.2640380859375\n",
      "137 271.1144714355469\n",
      "138 260.42218017578125\n",
      "139 250.16326904296875\n",
      "140 240.3197479248047\n",
      "141 230.87112426757812\n",
      "142 221.8047332763672\n",
      "143 213.10646057128906\n",
      "144 204.75425720214844\n",
      "145 196.73709106445312\n",
      "146 189.04824829101562\n",
      "147 181.66128540039062\n",
      "148 174.5670166015625\n",
      "149 167.75949096679688\n",
      "150 161.22369384765625\n",
      "151 154.9468994140625\n",
      "152 148.92214965820312\n",
      "153 143.1351318359375\n",
      "154 137.57777404785156\n",
      "155 132.23831176757812\n",
      "156 127.1107177734375\n",
      "157 122.18580627441406\n",
      "158 117.45662689208984\n",
      "159 112.91346740722656\n",
      "160 108.54866027832031\n",
      "161 104.35554504394531\n",
      "162 100.3267593383789\n",
      "163 96.4558334350586\n",
      "164 92.73863983154297\n",
      "165 89.16629028320312\n",
      "166 85.73257446289062\n",
      "167 82.43406677246094\n",
      "168 79.2636947631836\n",
      "169 76.21737670898438\n",
      "170 73.28996276855469\n",
      "171 70.4769287109375\n",
      "172 67.77310180664062\n",
      "173 65.17371368408203\n",
      "174 62.6772346496582\n",
      "175 60.27571487426758\n",
      "176 57.96813201904297\n",
      "177 55.7503662109375\n",
      "178 53.61830139160156\n",
      "179 51.56871032714844\n",
      "180 49.59767532348633\n",
      "181 47.70398712158203\n",
      "182 45.88387680053711\n",
      "183 44.132781982421875\n",
      "184 42.449642181396484\n",
      "185 40.831573486328125\n",
      "186 39.275634765625\n",
      "187 37.77976608276367\n",
      "188 36.34202194213867\n",
      "189 34.95856475830078\n",
      "190 33.628746032714844\n",
      "191 32.350181579589844\n",
      "192 31.12053680419922\n",
      "193 29.9375\n",
      "194 28.80051040649414\n",
      "195 27.707048416137695\n",
      "196 26.655651092529297\n",
      "197 25.64436149597168\n",
      "198 24.671781539916992\n",
      "199 23.73641014099121\n",
      "200 22.836524963378906\n",
      "201 21.971820831298828\n",
      "202 21.13982391357422\n",
      "203 20.338977813720703\n",
      "204 19.569374084472656\n",
      "205 18.82883071899414\n",
      "206 18.117116928100586\n",
      "207 17.43243408203125\n",
      "208 16.773775100708008\n",
      "209 16.140575408935547\n",
      "210 15.530962944030762\n",
      "211 14.944984436035156\n",
      "212 14.381082534790039\n",
      "213 13.838762283325195\n",
      "214 13.317131996154785\n",
      "215 12.81501579284668\n",
      "216 12.332279205322266\n",
      "217 11.86760139465332\n",
      "218 11.420543670654297\n",
      "219 10.990255355834961\n",
      "220 10.576732635498047\n",
      "221 10.178646087646484\n",
      "222 9.795621871948242\n",
      "223 9.427181243896484\n",
      "224 9.07278060913086\n",
      "225 8.731634140014648\n",
      "226 8.403423309326172\n",
      "227 8.087485313415527\n",
      "228 7.783725261688232\n",
      "229 7.491145133972168\n",
      "230 7.209824085235596\n",
      "231 6.939188003540039\n",
      "232 6.6787190437316895\n",
      "233 6.428248882293701\n",
      "234 6.187028408050537\n",
      "235 5.954757213592529\n",
      "236 5.731509208679199\n",
      "237 5.516545295715332\n",
      "238 5.309722900390625\n",
      "239 5.110862731933594\n",
      "240 4.91927433013916\n",
      "241 4.734927177429199\n",
      "242 4.557527542114258\n",
      "243 4.386850357055664\n",
      "244 4.222576141357422\n",
      "245 4.064355850219727\n",
      "246 3.912278890609741\n",
      "247 3.7660017013549805\n",
      "248 3.624946117401123\n",
      "249 3.4893932342529297\n",
      "250 3.358961343765259\n",
      "251 3.233283281326294\n",
      "252 3.1124701499938965\n",
      "253 2.9960806369781494\n",
      "254 2.8839964866638184\n",
      "255 2.7762551307678223\n",
      "256 2.672452688217163\n",
      "257 2.572844982147217\n",
      "258 2.4766855239868164\n",
      "259 2.384154796600342\n",
      "260 2.295132637023926\n",
      "261 2.209390163421631\n",
      "262 2.1269736289978027\n",
      "263 2.047581911087036\n",
      "264 1.9711616039276123\n",
      "265 1.8977041244506836\n",
      "266 1.8268375396728516\n",
      "267 1.758678913116455\n",
      "268 1.6931179761886597\n",
      "269 1.6300334930419922\n",
      "270 1.569266676902771\n",
      "271 1.5107426643371582\n",
      "272 1.4544392824172974\n",
      "273 1.4002043008804321\n",
      "274 1.3480064868927002\n",
      "275 1.297792673110962\n",
      "276 1.2494840621948242\n",
      "277 1.2029298543930054\n",
      "278 1.1581394672393799\n",
      "279 1.114936351776123\n",
      "280 1.0734096765518188\n",
      "281 1.0335012674331665\n",
      "282 0.9950039982795715\n",
      "283 0.9580186605453491\n",
      "284 0.9223006367683411\n",
      "285 0.888008713722229\n",
      "286 0.8549933433532715\n",
      "287 0.8231683969497681\n",
      "288 0.7925712466239929\n",
      "289 0.7631003260612488\n",
      "290 0.7347403168678284\n",
      "291 0.7074239253997803\n",
      "292 0.6811208724975586\n",
      "293 0.6558064818382263\n",
      "294 0.6314771175384521\n",
      "295 0.6080178022384644\n",
      "296 0.5854275226593018\n",
      "297 0.563666820526123\n",
      "298 0.5426830053329468\n",
      "299 0.5225522518157959\n",
      "300 0.5031601190567017\n",
      "301 0.48447635769844055\n",
      "302 0.4664266109466553\n",
      "303 0.4491316080093384\n",
      "304 0.43247655034065247\n",
      "305 0.416414350271225\n",
      "306 0.40092897415161133\n",
      "307 0.38611191511154175\n",
      "308 0.37175190448760986\n",
      "309 0.35793256759643555\n",
      "310 0.3446436822414398\n",
      "311 0.33189651370048523\n",
      "312 0.31956759095191956\n",
      "313 0.30770331621170044\n",
      "314 0.2962683141231537\n",
      "315 0.2853142023086548\n",
      "316 0.2746877074241638\n",
      "317 0.264529824256897\n",
      "318 0.25473636388778687\n",
      "319 0.24528947472572327\n",
      "320 0.23621873557567596\n",
      "321 0.2274758219718933\n",
      "322 0.21902765333652496\n",
      "323 0.21093502640724182\n",
      "324 0.20312748849391937\n",
      "325 0.19556695222854614\n",
      "326 0.18834900856018066\n",
      "327 0.1813645362854004\n",
      "328 0.17463544011116028\n",
      "329 0.16814793646335602\n",
      "330 0.16194477677345276\n",
      "331 0.1559702306985855\n",
      "332 0.15016844868659973\n",
      "333 0.14461852610111237\n",
      "334 0.13927331566810608\n",
      "335 0.1341199278831482\n",
      "336 0.12916846573352814\n",
      "337 0.124386265873909\n",
      "338 0.11977797001600266\n",
      "339 0.11536670476198196\n",
      "340 0.11109361797571182\n",
      "341 0.10699991136789322\n",
      "342 0.10304860770702362\n",
      "343 0.09923167526721954\n",
      "344 0.09556003659963608\n",
      "345 0.0920160561800003\n",
      "346 0.08861203491687775\n",
      "347 0.08533617109060287\n",
      "348 0.08220145106315613\n",
      "349 0.07917196303606033\n",
      "350 0.07625004649162292\n",
      "351 0.07342442870140076\n",
      "352 0.0707138329744339\n",
      "353 0.06811519712209702\n",
      "354 0.06558845937252045\n",
      "355 0.06316902488470078\n",
      "356 0.060841403901576996\n",
      "357 0.05859820917248726\n",
      "358 0.0564468577504158\n",
      "359 0.054347313940525055\n",
      "360 0.05235389992594719\n",
      "361 0.05043036490678787\n",
      "362 0.04856288433074951\n",
      "363 0.04677154868841171\n",
      "364 0.04504944384098053\n",
      "365 0.04338843375444412\n",
      "366 0.041785381734371185\n",
      "367 0.04025571048259735\n",
      "368 0.03877309337258339\n",
      "369 0.03734630346298218\n",
      "370 0.035974904894828796\n",
      "371 0.03465168550610542\n",
      "372 0.033389654010534286\n",
      "373 0.03215661644935608\n",
      "374 0.03097856417298317\n",
      "375 0.029844706878066063\n",
      "376 0.028754984959959984\n",
      "377 0.027688533067703247\n",
      "378 0.026681838557124138\n",
      "379 0.02570476196706295\n",
      "380 0.02476070635020733\n",
      "381 0.02385648339986801\n",
      "382 0.022986402735114098\n",
      "383 0.022156160324811935\n",
      "384 0.021348636597394943\n",
      "385 0.020576702430844307\n",
      "386 0.01981912925839424\n",
      "387 0.019095685333013535\n",
      "388 0.018407948315143585\n",
      "389 0.017738960683345795\n",
      "390 0.017092444002628326\n",
      "391 0.016476307064294815\n",
      "392 0.015874870121479034\n",
      "393 0.015302717685699463\n",
      "394 0.014742801897227764\n",
      "395 0.014211663044989109\n",
      "396 0.01370547991245985\n",
      "397 0.013205796480178833\n",
      "398 0.01273359078913927\n",
      "399 0.012282962910830975\n",
      "400 0.011843792162835598\n",
      "401 0.011416275054216385\n",
      "402 0.011005206033587456\n",
      "403 0.010612181387841702\n",
      "404 0.010231640189886093\n",
      "405 0.00987057201564312\n",
      "406 0.009522496722638607\n",
      "407 0.009186949580907822\n",
      "408 0.008858658373355865\n",
      "409 0.0085472846403718\n",
      "410 0.00824463926255703\n",
      "411 0.007958119735121727\n",
      "412 0.007671908941119909\n",
      "413 0.007402709219604731\n",
      "414 0.007139980792999268\n",
      "415 0.006891746539622545\n",
      "416 0.006653483957052231\n",
      "417 0.006421409081667662\n",
      "418 0.006208017934113741\n",
      "419 0.0059900712221860886\n",
      "420 0.005783327855169773\n",
      "421 0.005583382211625576\n",
      "422 0.005394143983721733\n",
      "423 0.005208657123148441\n",
      "424 0.005031941458582878\n",
      "425 0.004858050029724836\n",
      "426 0.004690330475568771\n",
      "427 0.00453362800180912\n",
      "428 0.004382113926112652\n",
      "429 0.0042317816987633705\n",
      "430 0.004091590642929077\n",
      "431 0.003955952823162079\n",
      "432 0.0038246819749474525\n",
      "433 0.0037023022305220366\n",
      "434 0.0035801425110548735\n",
      "435 0.0034584472887218\n",
      "436 0.003343710210174322\n",
      "437 0.003235134296119213\n",
      "438 0.003129086457192898\n",
      "439 0.0030295916367322206\n",
      "440 0.0029333012644201517\n",
      "441 0.002840119181200862\n",
      "442 0.0027505718171596527\n",
      "443 0.002662255195900798\n",
      "444 0.0025768964551389217\n",
      "445 0.002497035078704357\n",
      "446 0.002416834235191345\n",
      "447 0.0023413258604705334\n",
      "448 0.0022683441638946533\n",
      "449 0.002202320843935013\n",
      "450 0.002132813446223736\n",
      "451 0.0020680343732237816\n",
      "452 0.002003247383981943\n",
      "453 0.0019445510115474463\n",
      "454 0.0018881710711866617\n",
      "455 0.0018311433959752321\n",
      "456 0.0017766921082511544\n",
      "457 0.001723308814689517\n",
      "458 0.0016745305620133877\n",
      "459 0.0016260977135971189\n",
      "460 0.0015792670892551541\n",
      "461 0.0015330298338085413\n",
      "462 0.0014881412498652935\n",
      "463 0.0014451739843934774\n",
      "464 0.0014019851805642247\n",
      "465 0.001365093281492591\n",
      "466 0.0013265479356050491\n",
      "467 0.0012888213386759162\n",
      "468 0.0012535074492916465\n",
      "469 0.001219331519678235\n",
      "470 0.0011858058860525489\n",
      "471 0.0011534118093550205\n",
      "472 0.0011221168097108603\n",
      "473 0.001091488404199481\n",
      "474 0.0010633510537445545\n",
      "475 0.0010365224443376064\n",
      "476 0.0010084547102451324\n",
      "477 0.0009814195800572634\n",
      "478 0.0009561340557411313\n",
      "479 0.0009303278638981283\n",
      "480 0.000907851557713002\n",
      "481 0.0008818680071271956\n",
      "482 0.0008597568375989795\n",
      "483 0.000837900850456208\n",
      "484 0.0008167692576535046\n",
      "485 0.0007961539668031037\n",
      "486 0.0007745990878902376\n",
      "487 0.0007563884137198329\n",
      "488 0.0007375892018899322\n",
      "489 0.0007193437777459621\n",
      "490 0.0007015815353952348\n",
      "491 0.0006844325107522309\n",
      "492 0.0006686643464490771\n",
      "493 0.0006516951834782958\n",
      "494 0.0006366308662109077\n",
      "495 0.0006220921641215682\n",
      "496 0.0006068776128813624\n",
      "497 0.0005925347213633358\n",
      "498 0.0005779743078164756\n",
      "499 0.0005648995866067708\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0')\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "#Аналогично генерируем данные\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Генерируем веса\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Настраиваем параметры обучения\n",
    "lr = 1e-6\n",
    "epochs = 500\n",
    "\n",
    "# Запускаем обучающий цикл\n",
    "for epoch in range(epochs):\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "    \n",
    "    # Подсчитаем loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(epoch, loss)\n",
    "    \n",
    "    # Подсчитаем градиенты\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    \n",
    "    # Обновляем веса\n",
    "    w1 -= lr * grad_w1\n",
    "    w2 -= lr * grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преимущество использования автограда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(38434096., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "1 tensor(41306388., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "2 tensor(51119088., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "3 tensor(54829600., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "4 tensor(42874892., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "5 tensor(21843110., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "6 tensor(8351170., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "7 tensor(3291554.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "8 tensor(1782699.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "9 tensor(1256270., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "10 tensor(997637.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "11 tensor(826857.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "12 tensor(697299.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "13 tensor(593602.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "14 tensor(508864.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "15 tensor(438802.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "16 tensor(380450., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "17 tensor(331418.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "18 tensor(289920.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "19 tensor(254641.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "20 tensor(224453.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "21 tensor(198503.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "22 tensor(176105.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "23 tensor(156711.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "24 tensor(139828.3906, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "25 tensor(125068.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "26 tensor(112139.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "27 tensor(100787.1094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "28 tensor(90774.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "29 tensor(81914.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "30 tensor(74052.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "31 tensor(67056.6953, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "32 tensor(60823.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "33 tensor(55252.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "34 tensor(50266.2734, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "35 tensor(45794.5117, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "36 tensor(41777.6641, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "37 tensor(38168.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "38 tensor(34911.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "39 tensor(31968.3633, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "40 tensor(29305.9805, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "41 tensor(26893.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "42 tensor(24702.2383, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "43 tensor(22709.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "44 tensor(20893.8770, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "45 tensor(19239.4961, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "46 tensor(17728.5527, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "47 tensor(16347.9307, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "48 tensor(15084.7744, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "49 tensor(13928.5605, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "50 tensor(12868.9746, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "51 tensor(11896.8555, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "52 tensor(11004.4238, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "53 tensor(10184.1650, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "54 tensor(9430.0742, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "55 tensor(8736.5146, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "56 tensor(8097.8267, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "57 tensor(7509.2080, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "58 tensor(6966.7119, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "59 tensor(6466.2168, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "60 tensor(6004.8672, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "61 tensor(5578.5791, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "62 tensor(5184.6460, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "63 tensor(4820.4414, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "64 tensor(4483.4082, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "65 tensor(4171.5239, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "66 tensor(3882.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "67 tensor(3614.9543, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "68 tensor(3366.9746, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "69 tensor(3136.8789, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "70 tensor(2923.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "71 tensor(2725.3076, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "72 tensor(2541.2781, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "73 tensor(2370.1436, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "74 tensor(2211.1567, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "75 tensor(2063.4233, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "76 tensor(1926.0012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "77 tensor(1798.1892, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "78 tensor(1679.3573, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "79 tensor(1568.6628, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "80 tensor(1465.5935, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "81 tensor(1369.6353, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "82 tensor(1280.2302, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "83 tensor(1196.9236, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "84 tensor(1119.3059, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "85 tensor(1046.9194, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "86 tensor(979.4266, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "87 tensor(916.4475, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "88 tensor(857.6832, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "89 tensor(802.8563, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "90 tensor(751.6760, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "91 tensor(703.8840, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "92 tensor(659.2562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "93 tensor(617.5591, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "94 tensor(578.6171, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "95 tensor(542.2152, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "96 tensor(508.1810, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "97 tensor(476.3684, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "98 tensor(446.6199, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "99 tensor(418.8093, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "100 tensor(392.7735, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "101 tensor(368.4252, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "102 tensor(345.6384, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "103 tensor(324.3176, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "104 tensor(304.3512, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "105 tensor(285.6533, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "106 tensor(268.1425, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "107 tensor(251.7439, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "108 tensor(236.3568, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "109 tensor(221.9406, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "110 tensor(208.4365, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "111 tensor(195.7805, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "112 tensor(183.9154, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "113 tensor(172.7898, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "114 tensor(162.3636, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "115 tensor(152.5839, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "116 tensor(143.4084, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "117 tensor(134.8033, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "118 tensor(126.7304, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "119 tensor(119.1538, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "120 tensor(112.0448, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "121 tensor(105.3713, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "122 tensor(99.1083, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "123 tensor(93.2277, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "124 tensor(87.7051, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "125 tensor(82.5192, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "126 tensor(77.6483, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "127 tensor(73.0714, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "128 tensor(68.7731, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "129 tensor(64.7340, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "130 tensor(60.9400, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "131 tensor(57.3736, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "132 tensor(54.0212, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "133 tensor(50.8690, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "134 tensor(47.9065, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "135 tensor(45.1208, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "136 tensor(42.5020, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "137 tensor(40.0389, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "138 tensor(37.7232, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "139 tensor(35.5446, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "140 tensor(33.4944, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "141 tensor(31.5656, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "142 tensor(29.7504, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "143 tensor(28.0416, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "144 tensor(26.4343, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "145 tensor(24.9205, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "146 tensor(23.4958, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "147 tensor(22.1551, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "148 tensor(20.8923, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "149 tensor(19.7031, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "150 tensor(18.5833, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "151 tensor(17.5282, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "152 tensor(16.5338, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "153 tensor(15.5976, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "154 tensor(14.7158, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "155 tensor(13.8847, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "156 tensor(13.1019, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "157 tensor(12.3640, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "158 tensor(11.6686, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "159 tensor(11.0131, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "160 tensor(10.3952, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "161 tensor(9.8121, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "162 tensor(9.2629, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "163 tensor(8.7453, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "164 tensor(8.2570, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "165 tensor(7.7966, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "166 tensor(7.3619, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "167 tensor(6.9525, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "168 tensor(6.5661, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "169 tensor(6.2019, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "170 tensor(5.8576, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "171 tensor(5.5331, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "172 tensor(5.2271, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "173 tensor(4.9382, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "174 tensor(4.6658, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "175 tensor(4.4085, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "176 tensor(4.1658, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "177 tensor(3.9363, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "178 tensor(3.7200, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "179 tensor(3.5157, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "180 tensor(3.3230, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "181 tensor(3.1409, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "182 tensor(2.9690, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "183 tensor(2.8066, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "184 tensor(2.6534, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "185 tensor(2.5085, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "186 tensor(2.3716, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "187 tensor(2.2426, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "188 tensor(2.1207, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "189 tensor(2.0055, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "190 tensor(1.8965, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "191 tensor(1.7936, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "192 tensor(1.6964, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "193 tensor(1.6045, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "194 tensor(1.5178, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "195 tensor(1.4357, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "196 tensor(1.3582, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "197 tensor(1.2849, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "198 tensor(1.2157, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "199 tensor(1.1501, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "200 tensor(1.0883, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "201 tensor(1.0297, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "202 tensor(0.9745, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "203 tensor(0.9221, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "204 tensor(0.8728, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "205 tensor(0.8260, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "206 tensor(0.7817, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "207 tensor(0.7399, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "208 tensor(0.7004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "209 tensor(0.6630, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "210 tensor(0.6277, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "211 tensor(0.5941, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "212 tensor(0.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "213 tensor(0.5327, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "214 tensor(0.5042, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "215 tensor(0.4774, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "216 tensor(0.4521, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "217 tensor(0.4281, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "218 tensor(0.4054, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "219 tensor(0.3839, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "220 tensor(0.3636, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "221 tensor(0.3443, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "222 tensor(0.3262, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "223 tensor(0.3089, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "224 tensor(0.2926, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "225 tensor(0.2771, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "226 tensor(0.2626, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "227 tensor(0.2487, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "228 tensor(0.2356, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "229 tensor(0.2232, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "230 tensor(0.2115, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "231 tensor(0.2004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "232 tensor(0.1899, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "233 tensor(0.1799, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "234 tensor(0.1705, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "235 tensor(0.1616, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "236 tensor(0.1531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "237 tensor(0.1451, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "238 tensor(0.1375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "239 tensor(0.1303, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "240 tensor(0.1235, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "241 tensor(0.1171, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "242 tensor(0.1110, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "243 tensor(0.1052, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "244 tensor(0.0997, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "245 tensor(0.0945, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "246 tensor(0.0896, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "247 tensor(0.0849, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "248 tensor(0.0805, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "249 tensor(0.0763, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "250 tensor(0.0724, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "251 tensor(0.0686, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "252 tensor(0.0651, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "253 tensor(0.0617, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "254 tensor(0.0585, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "255 tensor(0.0555, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "256 tensor(0.0526, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "257 tensor(0.0499, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "258 tensor(0.0473, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "259 tensor(0.0449, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "260 tensor(0.0426, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "261 tensor(0.0404, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "262 tensor(0.0383, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "263 tensor(0.0363, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "264 tensor(0.0345, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "265 tensor(0.0327, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "266 tensor(0.0310, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "267 tensor(0.0294, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "268 tensor(0.0279, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "269 tensor(0.0265, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "270 tensor(0.0251, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "271 tensor(0.0238, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "272 tensor(0.0226, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "273 tensor(0.0215, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "274 tensor(0.0204, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "275 tensor(0.0193, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "276 tensor(0.0184, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "277 tensor(0.0174, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "278 tensor(0.0166, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "279 tensor(0.0157, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "280 tensor(0.0149, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "281 tensor(0.0142, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "282 tensor(0.0134, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "283 tensor(0.0128, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "284 tensor(0.0121, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "285 tensor(0.0115, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "286 tensor(0.0109, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "287 tensor(0.0104, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "288 tensor(0.0099, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "289 tensor(0.0094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "290 tensor(0.0089, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "291 tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "292 tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "293 tensor(0.0077, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "294 tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "295 tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "296 tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "297 tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "298 tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "299 tensor(0.0057, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "300 tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "301 tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "302 tensor(0.0049, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "303 tensor(0.0047, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "304 tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "305 tensor(0.0042, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "306 tensor(0.0040, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "307 tensor(0.0038, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "308 tensor(0.0037, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "309 tensor(0.0035, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "310 tensor(0.0033, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "311 tensor(0.0032, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "312 tensor(0.0030, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "313 tensor(0.0029, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "314 tensor(0.0028, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "315 tensor(0.0026, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "316 tensor(0.0025, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "317 tensor(0.0024, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "318 tensor(0.0023, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "319 tensor(0.0022, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "320 tensor(0.0021, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "321 tensor(0.0020, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "322 tensor(0.0019, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "323 tensor(0.0018, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "324 tensor(0.0018, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "325 tensor(0.0017, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "326 tensor(0.0016, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "327 tensor(0.0015, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "328 tensor(0.0015, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "329 tensor(0.0014, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "330 tensor(0.0014, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "331 tensor(0.0013, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "332 tensor(0.0013, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "333 tensor(0.0012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "334 tensor(0.0012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "335 tensor(0.0011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "336 tensor(0.0011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "337 tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "338 tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "339 tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "340 tensor(0.0009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "341 tensor(0.0009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "342 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "343 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "344 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "345 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "346 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "347 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "348 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "349 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "350 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "351 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "352 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "353 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "354 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "355 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "356 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "357 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "358 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "359 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "360 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "361 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "362 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "363 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "364 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "365 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "366 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "367 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "368 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "369 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "370 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "371 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "372 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "373 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "374 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "375 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "376 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "377 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "378 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "379 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "380 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "381 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "382 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "383 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "384 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "385 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "386 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "387 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "388 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "389 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "390 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "391 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "392 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "393 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "394 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "395 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "396 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "397 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "398 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "399 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "400 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "401 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "402 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "403 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "404 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "405 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "406 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "407 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "408 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "409 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "410 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "411 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "412 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "413 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "414 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "415 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "416 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "417 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "418 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "419 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "420 tensor(9.8071e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "421 tensor(9.6621e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "422 tensor(9.4554e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "423 tensor(9.3070e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "424 tensor(9.0831e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "425 tensor(8.9179e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "426 tensor(8.7285e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "427 tensor(8.5804e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "428 tensor(8.4144e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "429 tensor(8.2581e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "430 tensor(8.1440e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "431 tensor(7.9748e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "432 tensor(7.8230e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "433 tensor(7.6996e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "434 tensor(7.5605e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "435 tensor(7.4041e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "436 tensor(7.2971e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "437 tensor(7.1652e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "438 tensor(7.0543e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "439 tensor(6.9395e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "440 tensor(6.8079e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "441 tensor(6.6927e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "442 tensor(6.5853e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "443 tensor(6.4585e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "444 tensor(6.3632e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "445 tensor(6.2513e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "446 tensor(6.1698e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "447 tensor(6.0590e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "448 tensor(5.9605e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "449 tensor(5.8781e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "450 tensor(5.7951e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "451 tensor(5.6836e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "452 tensor(5.5982e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "453 tensor(5.5211e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "454 tensor(5.4209e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "455 tensor(5.3448e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "456 tensor(5.2642e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "457 tensor(5.1969e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "458 tensor(5.1027e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "459 tensor(5.0430e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "460 tensor(4.9448e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "461 tensor(4.8784e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "462 tensor(4.8046e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "463 tensor(4.7364e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "464 tensor(4.6607e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "465 tensor(4.5842e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "466 tensor(4.5256e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "467 tensor(4.4806e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "468 tensor(4.3915e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "469 tensor(4.3374e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "470 tensor(4.2624e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "471 tensor(4.2195e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "472 tensor(4.1740e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "473 tensor(4.1315e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "474 tensor(4.0761e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "475 tensor(4.0117e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "476 tensor(3.9616e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "477 tensor(3.9209e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "478 tensor(3.8741e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "479 tensor(3.8295e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "480 tensor(3.7860e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "481 tensor(3.7283e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "482 tensor(3.6861e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "483 tensor(3.6233e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "484 tensor(3.5858e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "485 tensor(3.5383e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "486 tensor(3.4885e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "487 tensor(3.4700e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "488 tensor(3.4161e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "489 tensor(3.3786e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "490 tensor(3.3455e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "491 tensor(3.3100e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "492 tensor(3.2644e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "493 tensor(3.2185e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "494 tensor(3.1902e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "495 tensor(3.1447e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "496 tensor(3.1152e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "497 tensor(3.0949e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "498 tensor(3.0652e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "499 tensor(3.0204e-05, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0')\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "lr = 1e-6\n",
    "epochs = 500\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    # Так же проходим forward pass, но теперь нет необходимости хранить промежуточные значения\n",
    "    # потому что мы будем использовать автоград\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(epoch, loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= lr * w1.grad\n",
    "        w2 -= lr * w2.grad\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(32795936., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "1 tensor(25020650., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "2 tensor(20667412., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "3 tensor(17617548., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "4 tensor(15294176., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "5 tensor(13443612., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "6 tensor(11922718., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "7 tensor(10648485., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "8 tensor(9559418., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "9 tensor(8618542., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "10 tensor(7802354., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "11 tensor(7085511.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "12 tensor(6449344., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "13 tensor(5885885., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "14 tensor(5383743., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "15 tensor(4933069.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "16 tensor(4526313.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "17 tensor(4160222.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "18 tensor(3827182.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "19 tensor(3525042.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "20 tensor(3249670.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "21 tensor(2998851.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "22 tensor(2770200.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "23 tensor(2560481.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "24 tensor(2369140., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "25 tensor(2193882., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "26 tensor(2033400.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "27 tensor(1884722.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "28 tensor(1749174.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "29 tensor(1623068.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "30 tensor(1507750.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "31 tensor(1401166.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "32 tensor(1302562.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "33 tensor(1210945.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "34 tensor(1127040.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "35 tensor(1049112.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "36 tensor(976804.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "37 tensor(910468.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "38 tensor(848256.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "39 tensor(790690.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "40 tensor(737425.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "41 tensor(687478.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "42 tensor(641716.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "43 tensor(598618.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "44 tensor(558677.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "45 tensor(521962., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "46 tensor(487243.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "47 tensor(455145.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "48 tensor(425463.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "49 tensor(397495.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "50 tensor(371590.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "51 tensor(347527.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "52 tensor(324945.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "53 tensor(303829.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "54 tensor(284224.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "55 tensor(265904.2812, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "56 tensor(248742.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "57 tensor(232777.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "58 tensor(217826.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "59 tensor(203945.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "60 tensor(190951.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "61 tensor(178866.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "62 tensor(167530.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "63 tensor(156877.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "64 tensor(147059.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "65 tensor(137924.9844, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "66 tensor(129358.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "67 tensor(121280.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "68 tensor(113768.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "69 tensor(106769.1797, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "70 tensor(100212.2812, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "71 tensor(93971.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "72 tensor(88216.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "73 tensor(82776.8906, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "74 tensor(77650.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "75 tensor(72920.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "76 tensor(68468.8594, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "77 tensor(64284.6055, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "78 tensor(60338.0195, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "79 tensor(56670.9727, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "80 tensor(53241.1406, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "81 tensor(49999.7383, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "82 tensor(46962.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "83 tensor(44134.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "84 tensor(41458.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "85 tensor(38974.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "86 tensor(36649.6836, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "87 tensor(34453.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "88 tensor(32389.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "89 tensor(30457.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "90 tensor(28652.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "91 tensor(26950.1211, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "92 tensor(25359.6289, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "93 tensor(23867.2773, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "94 tensor(22458.1914, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "95 tensor(21123.7695, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "96 tensor(19887.6211, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "97 tensor(18728.0742, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "98 tensor(17631.8652, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "99 tensor(16599.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "100 tensor(15633.1289, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "101 tensor(14723.9912, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "102 tensor(13869.0801, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "103 tensor(13071.1309, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "104 tensor(12313.4395, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "105 tensor(11600.2051, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "106 tensor(10932.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "107 tensor(10303.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "108 tensor(9712.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "109 tensor(9153.3711, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "110 tensor(8640.4492, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "111 tensor(8148.9316, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "112 tensor(7684.4863, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "113 tensor(7244.2124, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "114 tensor(6831.6514, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "115 tensor(6444.6099, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "116 tensor(6080.7378, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "117 tensor(5736.7202, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "118 tensor(5414.1396, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "119 tensor(5111.8809, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "120 tensor(4825.0723, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "121 tensor(4555.1938, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "122 tensor(4301.9043, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "123 tensor(4061.2568, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "124 tensor(3834.6787, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "125 tensor(3620.4819, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "126 tensor(3419.3235, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "127 tensor(3229.2659, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "128 tensor(3049.6089, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "129 tensor(2880.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "130 tensor(2721.1003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "131 tensor(2571.1555, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "132 tensor(2428.6138, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "133 tensor(2293.7622, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "134 tensor(2166.8735, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "135 tensor(2047.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "136 tensor(1934.4871, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "137 tensor(1827.9666, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "138 tensor(1727.4734, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "139 tensor(1632.0964, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "140 tensor(1542.0059, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "141 tensor(1456.9700, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "142 tensor(1376.3712, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "143 tensor(1300.3291, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "144 tensor(1228.3035, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "145 tensor(1161.0876, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "146 tensor(1096.8185, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "147 tensor(1036.1396, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "148 tensor(978.7552, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "149 tensor(924.4125, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "150 tensor(873.1943, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "151 tensor(824.6588, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "152 tensor(778.7706, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "153 tensor(735.3247, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "154 tensor(694.4305, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "155 tensor(655.6776, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "156 tensor(618.9744, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "157 tensor(584.2793, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "158 tensor(551.4912, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "159 tensor(520.5238, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "160 tensor(491.2826, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "161 tensor(463.6780, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "162 tensor(437.5768, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "163 tensor(412.7613, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "164 tensor(389.3362, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "165 tensor(367.3936, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "166 tensor(346.5310, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "167 tensor(326.7641, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "168 tensor(308.1735, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "169 tensor(290.4859, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "170 tensor(273.7855, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "171 tensor(257.9901, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "172 tensor(243.0931, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "173 tensor(229.0208, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "174 tensor(215.7053, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "175 tensor(203.1441, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "176 tensor(191.2821, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "177 tensor(180.0843, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "178 tensor(169.5110, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "179 tensor(159.5228, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "180 tensor(150.0913, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "181 tensor(141.1939, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "182 tensor(132.7946, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "183 tensor(124.8755, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "184 tensor(117.4015, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "185 tensor(110.3499, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "186 tensor(103.7016, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "187 tensor(97.4325, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "188 tensor(91.5253, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "189 tensor(85.9536, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "190 tensor(80.7059, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "191 tensor(75.7593, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "192 tensor(71.0991, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "193 tensor(66.7117, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "194 tensor(62.5802, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "195 tensor(58.6866, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "196 tensor(55.0287, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "197 tensor(51.5841, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "198 tensor(48.3440, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "199 tensor(45.3081, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "200 tensor(42.4466, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "201 tensor(39.7462, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "202 tensor(37.2080, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "203 tensor(34.8217, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "204 tensor(32.5831, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "205 tensor(30.4789, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "206 tensor(28.5010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "207 tensor(26.6439, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "208 tensor(24.8999, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "209 tensor(23.2645, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "210 tensor(21.7303, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "211 tensor(20.2915, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "212 tensor(18.9418, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "213 tensor(17.6772, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "214 tensor(16.4915, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "215 tensor(15.3810, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "216 tensor(14.3407, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "217 tensor(13.3671, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "218 tensor(12.4548, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "219 tensor(11.6019, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "220 tensor(10.8044, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "221 tensor(10.0580, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "222 tensor(9.3598, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "223 tensor(8.7073, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "224 tensor(8.0975, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "225 tensor(7.5280, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "226 tensor(6.9967, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "227 tensor(6.5001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "228 tensor(6.0371, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "229 tensor(5.6050, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "230 tensor(5.2022, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "231 tensor(4.8263, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "232 tensor(4.4762, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "233 tensor(4.1501, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "234 tensor(3.8463, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "235 tensor(3.5636, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "236 tensor(3.3004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "237 tensor(3.0555, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "238 tensor(2.8276, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "239 tensor(2.6161, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "240 tensor(2.4192, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "241 tensor(2.2365, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "242 tensor(2.0666, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "243 tensor(1.9092, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "244 tensor(1.7629, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "245 tensor(1.6272, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "246 tensor(1.5016, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "247 tensor(1.3849, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "248 tensor(1.2767, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "249 tensor(1.1767, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "250 tensor(1.0841, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "251 tensor(0.9983, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "252 tensor(0.9189, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "253 tensor(0.8454, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "254 tensor(0.7776, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "255 tensor(0.7150, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "256 tensor(0.6570, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "257 tensor(0.6036, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "258 tensor(0.5542, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "259 tensor(0.5087, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "260 tensor(0.4667, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "261 tensor(0.4279, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "262 tensor(0.3924, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "263 tensor(0.3595, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "264 tensor(0.3293, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "265 tensor(0.3015, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "266 tensor(0.2759, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "267 tensor(0.2523, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "268 tensor(0.2307, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "269 tensor(0.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "270 tensor(0.1926, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "271 tensor(0.1759, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "272 tensor(0.1605, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "273 tensor(0.1464, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "274 tensor(0.1335, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "275 tensor(0.1217, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "276 tensor(0.1108, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "277 tensor(0.1009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "278 tensor(0.0919, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "279 tensor(0.0836, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "280 tensor(0.0760, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "281 tensor(0.0691, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "282 tensor(0.0628, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "283 tensor(0.0570, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "284 tensor(0.0517, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "285 tensor(0.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "286 tensor(0.0425, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "287 tensor(0.0386, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "288 tensor(0.0349, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "289 tensor(0.0316, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "290 tensor(0.0286, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "291 tensor(0.0259, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "292 tensor(0.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "293 tensor(0.0212, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "294 tensor(0.0191, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "295 tensor(0.0172, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "296 tensor(0.0155, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "297 tensor(0.0140, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "298 tensor(0.0126, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "299 tensor(0.0114, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "300 tensor(0.0103, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "301 tensor(0.0092, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "302 tensor(0.0083, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "303 tensor(0.0075, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "304 tensor(0.0067, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "305 tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "306 tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "307 tensor(0.0049, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "308 tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "309 tensor(0.0039, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "310 tensor(0.0035, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "311 tensor(0.0031, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "312 tensor(0.0028, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "313 tensor(0.0025, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "314 tensor(0.0023, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "315 tensor(0.0020, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "316 tensor(0.0018, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "317 tensor(0.0016, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "318 tensor(0.0014, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "319 tensor(0.0013, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "320 tensor(0.0011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "321 tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "322 tensor(0.0009, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "323 tensor(0.0008, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "324 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "325 tensor(0.0007, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "326 tensor(0.0006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "327 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "328 tensor(0.0005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "329 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "330 tensor(0.0004, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "331 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "332 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "333 tensor(0.0003, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "334 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "335 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "336 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "337 tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "338 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "339 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "340 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "341 tensor(0.0001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "342 tensor(9.4803e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "343 tensor(8.5339e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "344 tensor(7.6760e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "345 tensor(6.8691e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "346 tensor(6.1957e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "347 tensor(5.6089e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "348 tensor(5.0032e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "349 tensor(4.5326e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "350 tensor(4.0938e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "351 tensor(3.7256e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "352 tensor(3.3540e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "353 tensor(3.0482e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "354 tensor(2.7799e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "355 tensor(2.4916e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "356 tensor(2.2691e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "357 tensor(2.0854e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "358 tensor(1.8774e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "359 tensor(1.7266e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "360 tensor(1.5721e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "361 tensor(1.4540e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "362 tensor(1.3394e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "363 tensor(1.2240e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "364 tensor(1.1283e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "365 tensor(1.0288e-05, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "366 tensor(9.5639e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "367 tensor(8.7719e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "368 tensor(8.1484e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "369 tensor(7.5681e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "370 tensor(7.0059e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "371 tensor(6.5593e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "372 tensor(6.1269e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "373 tensor(5.6977e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "374 tensor(5.2508e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "375 tensor(4.9948e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "376 tensor(4.6067e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "377 tensor(4.3282e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "378 tensor(3.9564e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "379 tensor(3.7173e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "380 tensor(3.4841e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "381 tensor(3.3633e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "382 tensor(3.1207e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "383 tensor(3.0273e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "384 tensor(2.8014e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "385 tensor(2.6774e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "386 tensor(2.5015e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "387 tensor(2.3436e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "388 tensor(2.2853e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "389 tensor(2.1239e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "390 tensor(2.0605e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "391 tensor(1.8798e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "392 tensor(1.7931e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "393 tensor(1.7305e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "394 tensor(1.6225e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "395 tensor(1.5971e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "396 tensor(1.4956e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "397 tensor(1.4700e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "398 tensor(1.3822e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "399 tensor(1.3490e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "400 tensor(1.2299e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "401 tensor(1.2021e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "402 tensor(1.1330e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "403 tensor(1.1016e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "404 tensor(1.0428e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "405 tensor(1.0067e-06, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "406 tensor(9.8295e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "407 tensor(9.1810e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "408 tensor(8.7296e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "409 tensor(8.2553e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "410 tensor(8.1968e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "411 tensor(7.7803e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "412 tensor(7.6673e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "413 tensor(7.2835e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "414 tensor(6.8988e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "415 tensor(6.7754e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "416 tensor(6.4832e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "417 tensor(6.2411e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "418 tensor(5.7783e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "419 tensor(5.7406e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "420 tensor(5.5602e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "421 tensor(5.1833e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "422 tensor(5.1311e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "423 tensor(5.2799e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "424 tensor(4.9001e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "425 tensor(4.7755e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "426 tensor(4.7568e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "427 tensor(4.7621e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "428 tensor(4.2072e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "429 tensor(3.9550e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "430 tensor(4.0940e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "431 tensor(3.9708e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "432 tensor(3.8105e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "433 tensor(3.6565e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "434 tensor(3.5783e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "435 tensor(3.4053e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "436 tensor(3.4222e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "437 tensor(3.2619e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "438 tensor(3.1354e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "439 tensor(3.0882e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "440 tensor(2.9055e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "441 tensor(3.0511e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "442 tensor(2.8902e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "443 tensor(3.0530e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "444 tensor(2.9197e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "445 tensor(2.6490e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "446 tensor(2.6087e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "447 tensor(2.7616e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "448 tensor(2.5289e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "449 tensor(2.5148e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "450 tensor(2.1816e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "451 tensor(2.1475e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "452 tensor(2.2168e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "453 tensor(2.0303e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "454 tensor(2.0579e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "455 tensor(2.2545e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "456 tensor(2.1880e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "457 tensor(2.1464e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "458 tensor(2.1221e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "459 tensor(1.7618e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "460 tensor(1.9326e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "461 tensor(1.6941e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "462 tensor(1.7873e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "463 tensor(1.9016e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "464 tensor(1.8156e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "465 tensor(1.7975e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "466 tensor(1.6796e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "467 tensor(1.6713e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "468 tensor(1.6490e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "469 tensor(1.6169e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "470 tensor(1.7893e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "471 tensor(1.7688e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "472 tensor(1.7823e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "473 tensor(1.8721e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "474 tensor(1.8530e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "475 tensor(1.8741e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "476 tensor(1.5735e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "477 tensor(1.7586e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "478 tensor(1.9050e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "479 tensor(1.9996e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "480 tensor(2.0200e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "481 tensor(1.7448e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "482 tensor(1.7224e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "483 tensor(1.6969e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "484 tensor(1.6911e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "485 tensor(1.8165e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "486 tensor(1.8289e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "487 tensor(1.8045e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "488 tensor(1.7841e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "489 tensor(1.6802e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "490 tensor(1.6181e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "491 tensor(1.7197e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "492 tensor(1.7776e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "493 tensor(1.6372e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "494 tensor(1.6988e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "495 tensor(1.9947e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "496 tensor(1.7713e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "497 tensor(1.8304e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "498 tensor(2.0294e-07, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "499 tensor(2.0362e-07, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0')\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 500\n",
    "optimizer = optim.RMSprop([w1, w2], lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Так же проходим forward pass, но теперь нет необходимости хранить промежуточные значения\n",
    "    # потому что мы будем использовать автоград\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(epoch, loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
