{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbbi0U2p5ANz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799,\n",
       "       -0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)    \n",
    "np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGL-LBga_ZgQ"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z, grad=False):\n",
    "    if grad:\n",
    "        return sigmoid(z) * (1 - sigmoid(z))\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z, grad=False):\n",
    "    if grad:\n",
    "        return np.where(z <= 0, 0, 1)\n",
    "    return np.where(z <= 0, 0, z)\n",
    "\n",
    "def tanh(z, grad=False):\n",
    "    if grad:\n",
    "        return 1 - (tanh(z)) ** 2\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "def leaky_relu(z, slope, grad=False):\n",
    "    if grad:\n",
    "        return np.where(z <= 0, slope, 1)\n",
    "    return np.where(z <= 0, slope*z, z)\n",
    "\n",
    "def log_loss(a, y, grad=False):\n",
    "    if grad:\n",
    "        return (a - y) / (a * (1 - a))\n",
    "    return np.where(y == 0, -np.log(1 - a), -np.log(a))\n",
    "\n",
    "def init_weights(random=True):\n",
    "    global x, first_hidden, second_hidden\n",
    "    np.random.seed(0)\n",
    "    if random:\n",
    "        W_1 = np.random.random((x_dim, first_hidden))           # первая матрица весов, соединяющая 0 и 1 слой\n",
    "        b_1 = np.random.random((1, first_hidden))             # первый вектор смещений, соединяющая 0 и 1 слой\n",
    "        W_2 = np.random.random((first_hidden, second_hidden))   # вторая матрица весов, соединяющая 1 и 2 слой\n",
    "        b_2 = np.random.random((1, second_hidden))            # второй вектор весов, соединяющая 1 и 2 слой\n",
    "        return W_1, b_1, W_2, b_2\n",
    "    W_1 = np.zeros((x_dim, first_hidden))      \n",
    "    b_1 = np.zeros((1, first_hidden))          \n",
    "    W_2 = np.zeros((first_hidden, second_hidden)) \n",
    "    b_2 = np.zeros((1, second_hidden))            \n",
    "    return W_1, b_1, W_2, b_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gx3BVgIC5DbF"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# загрузка данных для бинарной классификации\n",
    "x = data['data']\n",
    "y = data['target'].reshape(-1, 1)\n",
    "x = (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "first_hidden = 64     # 4 нейрона в первом скрытом\n",
    "second_hidden = 1    # 1 нейрон на выходе\n",
    "\n",
    "x_n, x_dim = x.shape\n",
    "\n",
    "W_1, b_1, W_2, b_2 = init_weights(random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    '0_hidden': x_dim,\n",
    "    'n_layers': 2,\n",
    "    '1_hidden': 64,\n",
    "    '2_hidden': 1,\n",
    "    'weights': {}\n",
    "}\n",
    "\n",
    "\n",
    "def init_basic_weight(x_dim, z_dim):\n",
    "    return (np.random.random((x_dim, z_dim)), np.random.random((1, z_dim)))\n",
    "\n",
    "\n",
    "def init_model(parameters):\n",
    "    for i in range(model['n_layers']):\n",
    "        w_i, b_i = init_basic_weight(model[f'{i}_hidden'], model[f'{i+1}_hidden'])\n",
    "        \n",
    "        model['weights'].update({\n",
    "                f'W_{i}': w_i,\n",
    "                f'b_{i}': b_i\n",
    "            })\n",
    "    return model\n",
    "\n",
    "\n",
    "model = init_model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtNwE2uV5WOr"
   },
   "outputs": [],
   "source": [
    "# Юнит-тесты для проверки правильной спецификации параметров\n",
    "\n",
    "assert (x.shape == (x_n, x_dim))\n",
    "assert (y.shape == (x_n, 1))\n",
    "assert (W_1.shape == (x_dim, first_hidden))\n",
    "assert (b_1.shape == (1, first_hidden))\n",
    "assert (W_2.shape == (first_hidden, second_hidden))\n",
    "assert (b_2.shape == (1, second_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "E1gZ_NiYVaYt",
    "outputId": "e6531b64-c5da-4da9-c108-421c240ec566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.548, Iter: 10\n",
      "Log-loss: 0.265, Iter: 20\n",
      "Log-loss: 0.243, Iter: 30\n",
      "Log-loss: 0.236, Iter: 40\n",
      "Log-loss: 0.231, Iter: 50\n",
      "Log-loss: 0.227, Iter: 60\n",
      "Log-loss: 0.224, Iter: 70\n",
      "Log-loss: 0.222, Iter: 80\n",
      "Log-loss: 0.219, Iter: 90\n"
     ]
    }
   ],
   "source": [
    "W_1, b_1, W_2, b_2 = init_weights(random=True) \n",
    "\n",
    "PRINT_EVERY = 10\n",
    "EPOCHS = 100\n",
    "lr = 0.1\n",
    "slope = 0.05\n",
    "activation = 'tanh'\n",
    "\n",
    "def train_iters(W_1, b_1, W_2, b_2, EPOCHS, lr, slope, activation):\n",
    "    losses = []\n",
    "    for i in range(EPOCHS):\n",
    "        # forward pass\n",
    "        z_1 = x @ W_1 + b_1\n",
    "        a_1 = eval(activation)(z_1)\n",
    "        z_2 = a_1 @ W_2 + b_2\n",
    "        a_2 = sigmoid(z_2)\n",
    "        loss = log_loss(a_2, y).mean()\n",
    "        losses.append(loss)\n",
    "        if i % PRINT_EVERY == 0:\n",
    "            print('Log-loss: {:.3f}, Iter: {}'.format(loss, i))\n",
    "\n",
    "        # backward pass\n",
    "        da_2 = log_loss(a_2, y, grad=True)\n",
    "        dz_2 = da_2 * sigmoid(z_2, grad=True)\n",
    "        dw_2 = (1 / x_n) * a_1.T @ dz_2\n",
    "        db_2 = dz_2.mean(axis=0, keepdims=True)\n",
    "\n",
    "        dw_1 = (1 / x_n) * x.T @ (W_2.T * dz_2 * eval(activation)(z_1, grad=True))\n",
    "        db_1 = (W_2.T * dz_2 * eval(activation)(z_1, grad=True)).mean(axis=0, keepdims=True)\n",
    "\n",
    "        W_1 -= lr * dw_1\n",
    "        W_2 -= lr * dw_2\n",
    "        b_1 -= lr * db_1\n",
    "        b_2 -= lr * db_2\n",
    "    return losses\n",
    "\n",
    "losses = train_iters(W_1, b_1, W_2, b_2, EPOCHS, lr, slope, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DOoSPx9HRmuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 15.910, Iter: 10\n",
      "Log-loss: 15.910, Iter: 20\n",
      "Log-loss: 15.910, Iter: 30\n",
      "Log-loss: 15.910, Iter: 40\n",
      "Log-loss: 15.910, Iter: 50\n",
      "Log-loss: 15.910, Iter: 60\n",
      "Log-loss: 15.910, Iter: 70\n",
      "Log-loss: 15.910, Iter: 80\n",
      "Log-loss: 15.910, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.548, Iter: 10\n",
      "Log-loss: 0.265, Iter: 20\n",
      "Log-loss: 0.243, Iter: 30\n",
      "Log-loss: 0.236, Iter: 40\n",
      "Log-loss: 0.231, Iter: 50\n",
      "Log-loss: 0.227, Iter: 60\n",
      "Log-loss: 0.224, Iter: 70\n",
      "Log-loss: 0.222, Iter: 80\n",
      "Log-loss: 0.219, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.256, Iter: 10\n",
      "Log-loss: 0.233, Iter: 20\n",
      "Log-loss: 0.226, Iter: 30\n",
      "Log-loss: 0.220, Iter: 40\n",
      "Log-loss: 0.217, Iter: 50\n",
      "Log-loss: 0.214, Iter: 60\n",
      "Log-loss: 0.211, Iter: 70\n",
      "Log-loss: 0.209, Iter: 80\n",
      "Log-loss: 0.207, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.236, Iter: 10\n",
      "Log-loss: 0.224, Iter: 20\n",
      "Log-loss: 0.217, Iter: 30\n",
      "Log-loss: 0.213, Iter: 40\n",
      "Log-loss: 0.210, Iter: 50\n",
      "Log-loss: 0.207, Iter: 60\n",
      "Log-loss: 0.204, Iter: 70\n",
      "Log-loss: 0.202, Iter: 80\n",
      "Log-loss: 0.200, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.229, Iter: 10\n",
      "Log-loss: 0.218, Iter: 20\n",
      "Log-loss: 0.212, Iter: 30\n",
      "Log-loss: 0.208, Iter: 40\n",
      "Log-loss: 0.205, Iter: 50\n",
      "Log-loss: 0.202, Iter: 60\n",
      "Log-loss: 0.199, Iter: 70\n",
      "Log-loss: 0.197, Iter: 80\n",
      "Log-loss: 0.194, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.224, Iter: 10\n",
      "Log-loss: 0.214, Iter: 20\n",
      "Log-loss: 0.209, Iter: 30\n",
      "Log-loss: 0.205, Iter: 40\n",
      "Log-loss: 0.201, Iter: 50\n",
      "Log-loss: 0.198, Iter: 60\n",
      "Log-loss: 0.195, Iter: 70\n",
      "Log-loss: 0.195, Iter: 80\n",
      "Log-loss: 0.239, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.226, Iter: 10\n",
      "Log-loss: 0.218, Iter: 20\n",
      "Log-loss: 0.243, Iter: 30\n",
      "Log-loss: 0.244, Iter: 40\n",
      "Log-loss: 0.237, Iter: 50\n",
      "Log-loss: 0.235, Iter: 60\n",
      "Log-loss: 0.233, Iter: 70\n",
      "Log-loss: 0.230, Iter: 80\n",
      "Log-loss: 0.228, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.235, Iter: 10\n",
      "Log-loss: 0.295, Iter: 20\n",
      "Log-loss: 0.268, Iter: 30\n",
      "Log-loss: 0.261, Iter: 40\n",
      "Log-loss: 0.254, Iter: 50\n",
      "Log-loss: 0.250, Iter: 60\n",
      "Log-loss: 0.246, Iter: 70\n",
      "Log-loss: 0.243, Iter: 80\n",
      "Log-loss: 0.241, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.257, Iter: 10\n",
      "Log-loss: 0.330, Iter: 20\n",
      "Log-loss: 0.290, Iter: 30\n",
      "Log-loss: 0.278, Iter: 40\n",
      "Log-loss: 0.270, Iter: 50\n",
      "Log-loss: 0.264, Iter: 60\n",
      "Log-loss: 0.259, Iter: 70\n",
      "Log-loss: 0.255, Iter: 80\n",
      "Log-loss: 0.252, Iter: 90\n",
      "Log-loss: 15.910, Iter: 0\n",
      "Log-loss: 0.287, Iter: 10\n",
      "Log-loss: 0.350, Iter: 20\n",
      "Log-loss: 0.312, Iter: 30\n",
      "Log-loss: 0.294, Iter: 40\n",
      "Log-loss: 0.284, Iter: 50\n",
      "Log-loss: 0.277, Iter: 60\n",
      "Log-loss: 0.271, Iter: 70\n",
      "Log-loss: 0.266, Iter: 80\n",
      "Log-loss: 0.262, Iter: 90\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for i in np.arange(0, 1, 0.1):\n",
    "    W_1, b_1, W_2, b_2 = init_weights(random=True) \n",
    "    stats.append(min(train_iters(W_1, b_1, W_2, b_2, EPOCHS, i, slope, activation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR is 0.4\n"
     ]
    }
   ],
   "source": [
    "print('Best LR is', np.arange(0, 1, 0.1)[stats.index(min(stats))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN_numpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
