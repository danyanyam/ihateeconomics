{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_numpy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbbi0U2p5ANz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGL-LBga_ZgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z, grad=False):\n",
        "    if grad:\n",
        "        return sigmoid(z) * (1 - sigmoid(z))\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z, grad=False):\n",
        "    if grad:\n",
        "        return np.where(z <= 0, 0, 1)\n",
        "    return np.where(z <= 0, 0, z)\n",
        "\n",
        "def tanh(z, grad=False):\n",
        "    if grad:\n",
        "        return 1 - (tanh(z)) ** 2\n",
        "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
        "\n",
        "def leaky_relu(z, slope, grad=False):\n",
        "    if grad:\n",
        "        return np.where(z <= 0, slope, 1)\n",
        "    return np.where(z <= 0, slope*z, z)\n",
        "\n",
        "def log_loss(a, y, grad=False):\n",
        "    if grad:\n",
        "        return (a - y) / (a * (1 - a))\n",
        "    return np.where(y == 0, -np.log(1 - a), -np.log(a))\n",
        "\n",
        "def init_weights(random=True):\n",
        "    global x, first_hidden, second_hidden\n",
        "    if random:\n",
        "        W_1 = np.random.random((x_dim, first_hidden))           # первая матрица весов, соединяющая 0 и 1 слой\n",
        "        b_1 = np.random.random((1, first_hidden))             # первый вектор смещений, соединяющая 0 и 1 слой\n",
        "        W_2 = np.random.random((first_hidden, second_hidden))   # вторая матрица весов, соединяющая 1 и 2 слой\n",
        "        b_2 = np.random.random((1, second_hidden))            # второй вектор весов, соединяющая 1 и 2 слой\n",
        "        return W_1, b_1, W_2, b_2\n",
        "    W_1 = np.zeros((x_dim, first_hidden))      \n",
        "    b_1 = np.zeros((1, first_hidden))          \n",
        "    W_2 = np.zeros((first_hidden, second_hidden)) \n",
        "    b_2 = np.zeros((1, second_hidden))            \n",
        "    return W_1, b_1, W_2, b_2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3BVgIC5DbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# загрузка данных для бинарной классификации\n",
        "x = data['data']\n",
        "y = data['target'].reshape(-1, 1)\n",
        "x = (x - np.mean(x)) / np.std(x)\n",
        "\n",
        "first_hidden = 64     # 4 нейрона в первом скрытом\n",
        "second_hidden = 1    # 1 нейрон на выходе\n",
        "\n",
        "x_n, x_dim = x.shape\n",
        "\n",
        "W_1, b_1, W_2, b_2 = init_weights(random=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtNwE2uV5WOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Юнит-тесты для проверки правильной спецификации параметров\n",
        "\n",
        "assert (x.shape == (x_n, x_dim))\n",
        "assert (y.shape == (x_n, 1))\n",
        "assert (W_1.shape == (x_dim, first_hidden))\n",
        "assert (b_1.shape == (1, first_hidden))\n",
        "assert (W_2.shape == (first_hidden, second_hidden))\n",
        "assert (b_2.shape == (1, second_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1gZ_NiYVaYt",
        "colab_type": "code",
        "outputId": "e6531b64-c5da-4da9-c108-421c240ec566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "W_1, b_1, W_2, b_2 = init_weights(random=True) \n",
        "\n",
        "PRINT_EVERY = 10\n",
        "EPOCHS = 100\n",
        "lr = 0.1\n",
        "slope = 0.05\n",
        "activation = 'sigmoid'\n",
        "\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    # forward pass\n",
        "    z_1 = x @ W_1 + b_1\n",
        "    a_1 = eval(activation)(z_1)\n",
        "    z_2 = a_1 @ W_2 + b_2\n",
        "    a_2 = sigmoid(z_2)\n",
        "    loss = log_loss(a_2, y).mean()\n",
        "    if i % PRINT_EVERY == 0:\n",
        "        print('Log-loss: {:.3f}, Iter: {}'.format(loss, i))\n",
        "\n",
        "    # backward pass\n",
        "    da_2 = log_loss(a_2, y, grad=True)\n",
        "    dz_2 = da_2 * sigmoid(z_2, grad=True)\n",
        "    dw_2 = (1 / x_n) * a_1.T @ dz_2\n",
        "    db_2 = dz_2.mean(axis=0, keepdims=True)\n",
        "\n",
        "    dw_1 = (1 / x_n) * x.T @ (W_2.T * dz_2 * eval(activation)(z_1, grad=True))\n",
        "    db_1 = (W_2.T * dz_2 * eval(activation)(z_1, grad=True)).mean(axis=0, keepdims=True)\n",
        "    \n",
        "    W_1 -= lr * dw_1\n",
        "    W_2 -= lr * dw_2\n",
        "    b_1 -= lr * db_1\n",
        "    b_2 -= lr * db_2\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log-loss: 9.033, Iter: 0\n",
            "Log-loss: 2.629, Iter: 10\n",
            "Log-loss: 0.652, Iter: 20\n",
            "Log-loss: 0.522, Iter: 30\n",
            "Log-loss: 0.446, Iter: 40\n",
            "Log-loss: 0.399, Iter: 50\n",
            "Log-loss: 0.367, Iter: 60\n",
            "Log-loss: 0.343, Iter: 70\n",
            "Log-loss: 0.325, Iter: 80\n",
            "Log-loss: 0.311, Iter: 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOoSPx9HRmuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}