{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logloss_der.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X23hhtzkRAGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaLOqhahRRRu",
        "colab_type": "text"
      },
      "source": [
        "### Размеры матриц\n",
        "\n",
        "Пусть:\n",
        "1. Матрица X имеет размерность (m, n), где m - количество признаков, а n - количество данных\n",
        "2. Матрица Y имеет размерность (1, n)\n",
        "3. Матрица весов имеет размерность (m, 1)\n",
        "4. Смещение считаем отдельно\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ssKahadqhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_loss(a, y):\n",
        "    if y == 1:\n",
        "        return -y * np.log(a)\n",
        "    return -(1 - y) * np.log(1 - a)\n",
        "\n",
        "\n",
        "def log_loss_vect(a, y):\n",
        "    y_hat = np.squeeze(a).copy()\n",
        "    y = np.squeeze(y)\n",
        "\n",
        "    pos_inds = np.where(y == 1)\n",
        "    neg_inds = np.where(y == 0)\n",
        "\n",
        "    y_hat[pos_inds] = - np.log(y_hat[pos_inds])\n",
        "    y_hat[neg_inds] = - np.log(1 - y_hat[neg_inds])\n",
        "    return y_hat\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JZ9nxPwUOWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0001\n",
        "\n",
        "def forward_pass(x, w, b):\n",
        "    \"\"\"\n",
        "    Функция делает прямой проход\n",
        "    :params: w - матрица весов  (k, 1)\n",
        "             x - матрица данных (k, n)\n",
        "             b - скаляр\n",
        "    :return: z = WX + b - вектор (1, n)\n",
        "             a = sigmoid(z)\n",
        "    \"\"\"\n",
        "    # forward pass\n",
        "    z = w.T @ x + b\n",
        "    a = sigmoid(z)\n",
        "    return z, a\n",
        "\n",
        "def backward_pass(z, a, x):\n",
        "    \"\"\"\n",
        "    Функция делает обратный проход\n",
        "    :params: z - вектор (1, n)\n",
        "             a - вектор (1, n)\n",
        "             x - матрица данных (k, n)\n",
        "    :return: dw = dL/dw - вектор (k, 1)\n",
        "             db = dl/db - скаляр\n",
        "    \"\"\"\n",
        "    # backward pass\n",
        "    dz, dw, db = 0, 0, 0\n",
        "    dz = a - y\n",
        "    dw = (dz @ x.T).sum(axis=0)\n",
        "    db = dz.sum()\n",
        "    return dw, db\n",
        "\n",
        "def gradient_step(w, b, lr, dw, db):\n",
        "    \"\"\"\n",
        "    Функция обновляет веса\n",
        "    :params: lr - learning rate\n",
        "             dw = dL/dw - вектор (k, 1)\n",
        "             db = dl/db - скаляр\n",
        "             w - вектор весов (k, 1)\n",
        "             b - скаляр смещения\n",
        "    :return: w - вектор весов (k, 1)\n",
        "             b - скаляр смещения\n",
        "    \"\"\"\n",
        "    # gradient update\n",
        "    w -= lr * dw.reshape(-1, 1)\n",
        "    b -= lr * db\n",
        "    return w, b\n",
        "\n",
        "def train_iteration(x, y, w, b, lr=lr):\n",
        "    z, a = forward_pass(x, w, b)\n",
        "    dw, db = backward_pass(z, a, x)\n",
        "    w, b = gradient_step(w, b, lr, dw, db)\n",
        "    return w, b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQCvTVU4fjap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "921de993-47b3-4579-842e-6e55f82305fe"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# загрузка данных для бинарной классификации\n",
        "x = data['data'].T\n",
        "y = data['target'].T\n",
        "x = (x - np.mean(x)) / np.std(x)\n",
        "\n",
        "# Инициализация весов + гиперпараметры\n",
        "w = np.zeros((x.shape[0], 1))\n",
        "b = 0\n",
        "lr = 0.001\n",
        "\n",
        "# тренировочные итерации\n",
        "epochs = 100\n",
        "for i in range(epochs):\n",
        "\n",
        "    # обучение\n",
        "    w, b = train_iteration(x, y, w, b, lr=lr)\n",
        "\n",
        "    # отображение статистик\n",
        "    _, a = forward_pass(x, w, b)\n",
        "    if i % 20 == 0:\n",
        "        print('Eepoch: {}/{} | Log-Loss: {:.3f}'.format(i, epochs, log_loss_vect(a, y).mean()))\n"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eepoch: 0/100 | Log-Loss: 0.700\n",
            "Eepoch: 20/100 | Log-Loss: 0.284\n",
            "Eepoch: 40/100 | Log-Loss: 0.247\n",
            "Eepoch: 60/100 | Log-Loss: 0.230\n",
            "Eepoch: 80/100 | Log-Loss: 0.219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7DA1IyHiy2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}